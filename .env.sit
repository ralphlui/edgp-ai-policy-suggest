# Server Configuration
HOST=0.0.0.0
PORT=8092

# Environment
APP_ENV=sit


# API Configuration
API_TITLE=EDGP Policy Suggestion API
API_VERSION=1.0.0
API_DESCRIPTION=Data Quality Validation API using Great Expectations rules

# CORS Configuration
ALLOWED_ORIGINS=["http://localhost:3000","http://localhost:3001","http://localhost:8080","http://localhost:4200","http://localhost:5173","http://127.0.0.1:3000","http://127.0.0.1:8080","http://127.0.0.1:4200","http://127.0.0.1:5173","*"]


# These values will be populated by Kubernetes into .env files
AWS_REGION=AWS_REGION
AOSS_HOST=AOSS_HOST
AWS_ACCESS_KEY_ID=AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY=AWS_SECRET_ACCESS_KEY
# URL to validate user profiles and permissions  
ADMIN_URL=ADMIN_URL
# Rules Microservice
RULE_URL=RULE_URL

# Audit SQS Queue URL
AUDIT_SQS_URL=AUDIT_SQS_URL

# LLM Validation and Safety Configuration
LLM_VALIDATION_ENABLED=true
LLM_INPUT_MAX_LENGTH=10000
LLM_OUTPUT_MAX_LENGTH=50000
LLM_RATE_LIMIT_PER_MINUTE=60
LLM_RATE_LIMIT_PER_HOUR=1000
LLM_STRICT_MODE=false
LLM_AUTO_CORRECT=true
LLM_ADVANCED_SAFETY=true
LLM_SAFETY_THRESHOLD=0.7

OPENSEARCH_INDEX=edgp-column-metadata
EMBED_MODEL=text-embedding-3-small
EMBED_DIM=1536

# Policy History Configuration
POLICY_HISTORY_INDEX=edgp-policy-history
POLICY_RETENTION_DAYS=365
POLICY_MIN_SUCCESS_RATE=0.8
POLICY_TOP_K=3

# LLM Model Configuration
SCHEMA_LLM_MODEL=gpt-4o-mini
RULES_LLM_MODEL=gpt-4o-mini
# Lower temperature for more reliable structured output
LLM_TEMPERATURE=0.3
# Force JSON output mode
OPENAI_RESPONSE_FORMAT=json_object

# OpenAI API Key Configuration
OPENAI_SECRET_NAME=sit/edgp/secret

# JWT Token Authentication
JWT_ALGORITHM=RS256



LOG_LEVEL=info